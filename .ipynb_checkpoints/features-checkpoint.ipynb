{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import ndimage, spatial\n",
    "\n",
    "import transformations\n",
    "\n",
    "\n",
    "def inbounds(shape, indices):\n",
    "    assert len(shape) == len(indices)\n",
    "    for i, ind in enumerate(indices):\n",
    "        if ind < 0 or ind >= shape[i]:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Keypoint detectors ##########################################################\n",
    "\n",
    "class KeypointDetector(object):\n",
    "    def detectKeypoints(self, image):\n",
    "        '''\n",
    "        Input:\n",
    "            image -- uint8 BGR image with values between [0, 255]\n",
    "        Output:\n",
    "            list of detected keypoints, fill the cv2.KeyPoint objects with the\n",
    "            coordinates of the detected keypoints, the angle of the gradient\n",
    "            (in degrees), the detector response (Harris score for Harris detector)\n",
    "            and set the size to 10.\n",
    "        '''\n",
    "        raise NotImplementedError()\n",
    "\n",
    "class DummyKeypointDetector(KeypointDetector):\n",
    "    '''\n",
    "    Compute silly example features. This doesn't do anything meaningful, but\n",
    "    may be useful to use as an example.\n",
    "    '''\n",
    "\n",
    "    def detectKeypoints(self, image):\n",
    "        '''\n",
    "        Input:\n",
    "            image -- uint8 BGR image with values between [0, 255]\n",
    "        Output:\n",
    "            list of detected keypoints, fill the cv2.KeyPoint objects with the\n",
    "            coordinates of the detected keypoints, the angle of the gradient\n",
    "            (in degrees), the detector response (Harris score for Harris detector)\n",
    "            and set the size to 10.\n",
    "        '''\n",
    "        image = image.astype(np.float32)\n",
    "        image /= 255.\n",
    "        features = []\n",
    "        height, width = image.shape[:2]\n",
    "\n",
    "        for y in range(height):\n",
    "            for x in range(width):\n",
    "                r = image[y, x, 0]\n",
    "                g = image[y, x, 1]\n",
    "                b = image[y, x, 2]\n",
    "\n",
    "                if int(255 * (r + g + b) + 0.5) % 100 == 1:\n",
    "                    # If the pixel satisfies this meaningless criterion,\n",
    "                    # make it a feature.\n",
    "\n",
    "                    f = cv2.KeyPoint()\n",
    "                    f.pt = (x, y)\n",
    "                    # Dummy size\n",
    "                    f.size = 10\n",
    "                    f.angle = 0\n",
    "                    f.response = 10\n",
    "\n",
    "                    features.append(f)\n",
    "\n",
    "        return features\n",
    "\n",
    "\n",
    "class HarrisKeypointDetector(KeypointDetector):\n",
    "\n",
    "    # Compute harris values of an image.\n",
    "    def computeHarrisValues(self, srcImage):\n",
    "        '''\n",
    "        Input:\n",
    "            srcImage -- Grayscale input image in a numpy array with\n",
    "                        values in [0, 1]. The dimensions are (rows, cols).\n",
    "        Output:\n",
    "            harrisImage -- numpy array containing the Harris score at\n",
    "                           each pixel.\n",
    "            orientationImage -- numpy array containing the orientation of the\n",
    "                                gradient at each pixel in degrees.\n",
    "        '''\n",
    "        height, width = srcImage.shape[:2]\n",
    "\n",
    "        harrisImage = np.zeros(srcImage.shape[:2])\n",
    "        orientationImage = np.zeros(srcImage.shape[:2])\n",
    "\n",
    "        # TODO 1: Compute the harris corner strength for 'srcImage' at\n",
    "        # each pixel and store in 'harrisImage'.  See the project page\n",
    "        # for direction on how to do this. Also compute an orientation\n",
    "        # for each pixel and store it in 'orientationImage.'\n",
    "\n",
    "        Ix = ndimage.filters.sobel(srcImage,0)\n",
    "        Iy = ndimage.filters.sobel(srcImage,1)\n",
    "\n",
    "        Ix2 = Ix * Ix\n",
    "        Iy2 = Iy * Iy\n",
    "        IxIy = Ix * Iy\n",
    "        gaussianImage = ndimage.filters.gaussian_filter(srcImage, 0.5, truncate=3)\n",
    "        \n",
    "        harris1 = ndimage.filters.convolve(Ix2, gaussianImage)\n",
    "        harris2 = ndimage.filters.convolve(Iy2, gaussianImage)\n",
    "        harris3 = ndimage.filters.convolve(IxIy, gaussianImage)\n",
    "        \n",
    "        for i in range(len(height)):\n",
    "            for j in range(len(width)):\n",
    "                H = [[harris1[i][j], harris3[i][j]], [harris3[i][j],harris2[i][j]]]\n",
    "                harrisImage[i][j] = np.linalg.det(H) - 0.1 * (np.trace(H))**2\n",
    "\n",
    "        orientationImage = np.rad2deg(np.arctan2(Iy,Ix))\n",
    "\n",
    "        return harrisImage, orientationImage\n",
    "\n",
    "    def computeLocalMaxima(self, harrisImage):\n",
    "        '''\n",
    "        Input:\n",
    "            harrisImage -- numpy array containing the Harris score at\n",
    "                           each pixel.\n",
    "        Output:\n",
    "            destImage -- numpy array containing True/False at\n",
    "                         each pixel, depending on whether\n",
    "                         the pixel value is the local maxima in\n",
    "                         its 7x7 neighborhood.\n",
    "        '''\n",
    "        destImage = np.zeros_like(harrisImage, np.bool)\n",
    "\n",
    "        # TODO 2: Compute the local maxima image\n",
    "        # TODO-BLOCK-BEGIN\n",
    "        raise Exception(\"TODO in features.py not implemented\")\n",
    "        # TODO-BLOCK-END\n",
    "\n",
    "        return destImage\n",
    "\n",
    "    def detectKeypoints(self, image):\n",
    "        '''\n",
    "        Input:\n",
    "            image -- BGR image with values between [0, 255]\n",
    "        Output:\n",
    "            list of detected keypoints, fill the cv2.KeyPoint objects with the\n",
    "            coordinates of the detected keypoints, the angle of the gradient\n",
    "            (in degrees), the detector response (Harris score for Harris detector)\n",
    "            and set the size to 10.\n",
    "        '''\n",
    "        image = image.astype(np.float32)\n",
    "        image /= 255.\n",
    "        height, width = image.shape[:2]\n",
    "        features = []\n",
    "\n",
    "        # Create grayscale image used for Harris detection\n",
    "        grayImage = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # computeHarrisValues() computes the harris score at each pixel\n",
    "        # position, storing the result in harrisImage.\n",
    "        # You will need to implement this function.\n",
    "        harrisImage, orientationImage = self.computeHarrisValues(grayImage)\n",
    "\n",
    "        # Compute local maxima in the Harris image.  You will need to\n",
    "        # implement this function. Create image to store local maximum harris\n",
    "        # values as True, other pixels False\n",
    "        harrisMaxImage = self.computeLocalMaxima(harrisImage)\n",
    "\n",
    "        # Loop through feature points in harrisMaxImage and fill in information\n",
    "        # needed for descriptor computation for each point.\n",
    "        # You need to fill x, y, and angle.\n",
    "        for y in range(height):\n",
    "            for x in range(width):\n",
    "                if not harrisMaxImage[y, x]:\n",
    "                    continue\n",
    "\n",
    "                f = cv2.KeyPoint()\n",
    "\n",
    "                # TODO 3: Fill in feature f with location and orientation\n",
    "                # data here. Set f.size to 10, f.pt to the (x,y) coordinate,\n",
    "                # f.angle to the orientation in degrees and f.response to\n",
    "                # the Harris score\n",
    "                # TODO-BLOCK-BEGIN\n",
    "                raise Exception(\"TODO in features.py not implemented\")\n",
    "                # TODO-BLOCK-END\n",
    "\n",
    "                features.append(f)\n",
    "\n",
    "        return features\n",
    "\n",
    "\n",
    "class ORBKeypointDetector(KeypointDetector):\n",
    "    def detectKeypoints(self, image):\n",
    "        '''\n",
    "        Input:\n",
    "            image -- uint8 BGR image with values between [0, 255]\n",
    "        Output:\n",
    "            list of detected keypoints, fill the cv2.KeyPoint objects with the\n",
    "            coordinates of the detected keypoints, the angle of the gradient\n",
    "            (in degrees) and set the size to 10.\n",
    "        '''\n",
    "        detector = cv2.ORB()\n",
    "        return detector.detect(image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "## Feature descriptors #########################################################\n",
    "\n",
    "\n",
    "class FeatureDescriptor(object):\n",
    "    # Implement in child classes\n",
    "    def describeFeatures(self, image, keypoints):\n",
    "        '''\n",
    "        Input:\n",
    "            image -- BGR image with values between [0, 255]\n",
    "            keypoints -- the detected features, we have to compute the feature\n",
    "            descriptors at the specified coordinates\n",
    "        Output:\n",
    "            Descriptor numpy array, dimensions:\n",
    "                keypoint number x feature descriptor dimension\n",
    "        '''\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class SimpleFeatureDescriptor(FeatureDescriptor):\n",
    "    # TODO: Implement parts of this function\n",
    "    def describeFeatures(self, image, keypoints):\n",
    "        '''\n",
    "        Input:\n",
    "            image -- BGR image with values between [0, 255]\n",
    "            keypoints -- the detected features, we have to compute the feature\n",
    "                         descriptors at the specified coordinates\n",
    "        Output:\n",
    "            desc -- K x 25 numpy array, where K is the number of keypoints\n",
    "        '''\n",
    "        image = image.astype(np.float32)\n",
    "        image /= 255.\n",
    "        grayImage = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        desc = np.zeros((len(keypoints), 5 * 5))\n",
    "\n",
    "        for i, f in enumerate(keypoints):\n",
    "            x, y = f.pt\n",
    "\n",
    "            # TODO 4: The simple descriptor is a 5x5 window of intensities\n",
    "            # sampled centered on the feature point. Store the descriptor\n",
    "            # as a row-major vector. Treat pixels outside the image as zero.\n",
    "            # TODO-BLOCK-BEGIN\n",
    "            raise Exception(\"TODO in features.py not implemented\")\n",
    "            # TODO-BLOCK-END\n",
    "\n",
    "        return desc\n",
    "\n",
    "\n",
    "class MOPSFeatureDescriptor(FeatureDescriptor):\n",
    "    # TODO: Implement parts of this function\n",
    "    def describeFeatures(self, image, keypoints):\n",
    "        '''\n",
    "        Input:\n",
    "            image -- BGR image with values between [0, 255]\n",
    "            keypoints -- the detected features, we have to compute the feature\n",
    "            descriptors at the specified coordinates\n",
    "        Output:\n",
    "            desc -- K x W^2 numpy array, where K is the number of keypoints\n",
    "                    and W is the window size\n",
    "        '''\n",
    "        image = image.astype(np.float32)\n",
    "        image /= 255.\n",
    "        # This image represents the window around the feature you need to\n",
    "        # compute to store as the feature descriptor (row-major)\n",
    "        windowSize = 8\n",
    "        desc = np.zeros((len(keypoints), windowSize * windowSize))\n",
    "        grayImage = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        grayImage = ndimage.gaussian_filter(grayImage, 0.5)\n",
    "\n",
    "        for i, f in enumerate(keypoints):\n",
    "            # TODO 5: Compute the transform as described by the feature\n",
    "            # location/orientation. You will need to compute the transform\n",
    "            # from each pixel in the 40x40 rotated window surrounding\n",
    "            # the feature to the appropriate pixels in the 8x8 feature\n",
    "            # descriptor image.\n",
    "            transMx = np.zeros((2, 3))\n",
    "\n",
    "            # TODO-BLOCK-BEGIN\n",
    "            raise Exception(\"TODO in features.py not implemented\")\n",
    "            # TODO-BLOCK-END\n",
    "\n",
    "            # Call the warp affine function to do the mapping\n",
    "            # It expects a 2x3 matrix\n",
    "            destImage = cv2.warpAffine(grayImage, transMx,\n",
    "                (windowSize, windowSize), flags=cv2.INTER_LINEAR)\n",
    "\n",
    "            # TODO 6: Normalize the descriptor to have zero mean and unit\n",
    "            # variance. If the variance is zero then set the descriptor\n",
    "            # vector to zero. Lastly, write the vector to desc.\n",
    "            # TODO-BLOCK-BEGIN\n",
    "            raise Exception(\"TODO in features.py not implemented\")\n",
    "            # TODO-BLOCK-END\n",
    "\n",
    "        return desc\n",
    "\n",
    "\n",
    "class ORBFeatureDescriptor(KeypointDetector):\n",
    "    def describeFeatures(self, image, keypoints):\n",
    "        '''\n",
    "        Input:\n",
    "            image -- BGR image with values between [0, 255]\n",
    "            keypoints -- the detected features, we have to compute the feature\n",
    "            descriptors at the specified coordinates\n",
    "        Output:\n",
    "            Descriptor numpy array, dimensions:\n",
    "                keypoint number x feature descriptor dimension\n",
    "        '''\n",
    "        descriptor = cv2.ORB()\n",
    "        kps, desc = descriptor.compute(image, keypoints)\n",
    "        if desc is None:\n",
    "            desc = np.zeros((0, 128))\n",
    "\n",
    "        return desc\n",
    "\n",
    "\n",
    "# Compute Custom descriptors (extra credit)\n",
    "class CustomFeatureDescriptor(FeatureDescriptor):\n",
    "    def describeFeatures(self, image, keypoints):\n",
    "        '''\n",
    "        Input:\n",
    "            image -- BGR image with values between [0, 255]\n",
    "            keypoints -- the detected features, we have to compute the feature\n",
    "            descriptors at the specified coordinates\n",
    "        Output:\n",
    "            Descriptor numpy array, dimensions:\n",
    "                keypoint number x feature descriptor dimension\n",
    "        '''\n",
    "        raise NotImplementedError('NOT IMPLEMENTED')\n",
    "\n",
    "\n",
    "## Feature matchers ############################################################\n",
    "\n",
    "\n",
    "class FeatureMatcher(object):\n",
    "    def matchFeatures(self, desc1, desc2):\n",
    "        '''\n",
    "        Input:\n",
    "            desc1 -- the feature descriptors of image 1 stored in a numpy array,\n",
    "                dimensions: rows (number of key points) x\n",
    "                columns (dimension of the feature descriptor)\n",
    "            desc2 -- the feature descriptors of image 2 stored in a numpy array,\n",
    "                dimensions: rows (number of key points) x\n",
    "                columns (dimension of the feature descriptor)\n",
    "        Output:\n",
    "            features matches: a list of cv2.DMatch objects\n",
    "                How to set attributes:\n",
    "                    queryIdx: The index of the feature in the first image\n",
    "                    trainIdx: The index of the feature in the second image\n",
    "                    distance: The distance between the two features\n",
    "        '''\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # Evaluate a match using a ground truth homography.  This computes the\n",
    "    # average SSD distance between the matched feature points and\n",
    "    # the actual transformed positions.\n",
    "    @staticmethod\n",
    "    def evaluateMatch(features1, features2, matches, h):\n",
    "        d = 0\n",
    "        n = 0\n",
    "\n",
    "        for m in matches:\n",
    "            id1 = m.queryIdx\n",
    "            id2 = m.trainIdx\n",
    "            ptOld = np.array(features2[id2].pt)\n",
    "            ptNew = FeatureMatcher.applyHomography(features1[id1].pt, h)\n",
    "\n",
    "            # Euclidean distance\n",
    "            d += np.linalg.norm(ptNew - ptOld)\n",
    "            n += 1\n",
    "\n",
    "        return d / n if n != 0 else 0\n",
    "\n",
    "    # Transform point by homography.\n",
    "    @staticmethod\n",
    "    def applyHomography(pt, h):\n",
    "        x, y = pt\n",
    "        d = h[6]*x + h[7]*y + h[8]\n",
    "\n",
    "        return np.array([(h[0]*x + h[1]*y + h[2]) / d,\n",
    "            (h[3]*x + h[4]*y + h[5]) / d])\n",
    "\n",
    "\n",
    "class SSDFeatureMatcher(FeatureMatcher):\n",
    "    def matchFeatures(self, desc1, desc2):\n",
    "        '''\n",
    "        Input:\n",
    "            desc1 -- the feature descriptors of image 1 stored in a numpy array,\n",
    "                dimensions: rows (number of key points) x\n",
    "                columns (dimension of the feature descriptor)\n",
    "            desc2 -- the feature descriptors of image 2 stored in a numpy array,\n",
    "                dimensions: rows (number of key points) x\n",
    "                columns (dimension of the feature descriptor)\n",
    "        Output:\n",
    "            features matches: a list of cv2.DMatch objects\n",
    "                How to set attributes:\n",
    "                    queryIdx: The index of the feature in the first image\n",
    "                    trainIdx: The index of the feature in the second image\n",
    "                    distance: The distance between the two features\n",
    "        '''\n",
    "        matches = []\n",
    "        # feature count = n\n",
    "        assert desc1.ndim == 2\n",
    "        # feature count = m\n",
    "        assert desc2.ndim == 2\n",
    "        # the two features should have the type\n",
    "        assert desc1.shape[1] == desc2.shape[1]\n",
    "\n",
    "        if desc1.shape[0] == 0 or desc2.shape[0] == 0:\n",
    "            return []\n",
    "\n",
    "        # TODO 7: Perform simple feature matching.  This uses the SSD\n",
    "        # distance between two feature vectors, and matches a feature in\n",
    "        # the first image with the closest feature in the second image.\n",
    "        # Note: multiple features from the first image may match the same\n",
    "        # feature in the second image.\n",
    "        # TODO-BLOCK-BEGIN\n",
    "        raise Exception(\"TODO in features.py not implemented\")\n",
    "        # TODO-BLOCK-END\n",
    "\n",
    "        return matches\n",
    "\n",
    "\n",
    "class RatioFeatureMatcher(FeatureMatcher):\n",
    "    def matchFeatures(self, desc1, desc2):\n",
    "        '''\n",
    "        Input:\n",
    "            desc1 -- the feature descriptors of image 1 stored in a numpy array,\n",
    "                dimensions: rows (number of key points) x\n",
    "                columns (dimension of the feature descriptor)\n",
    "            desc2 -- the feature descriptors of image 2 stored in a numpy array,\n",
    "                dimensions: rows (number of key points) x\n",
    "                columns (dimension of the feature descriptor)\n",
    "        Output:\n",
    "            features matches: a list of cv2.DMatch objects\n",
    "                How to set attributes:\n",
    "                    queryIdx: The index of the feature in the first image\n",
    "                    trainIdx: The index of the feature in the second image\n",
    "                    distance: The ratio test score\n",
    "        '''\n",
    "        matches = []\n",
    "        # feature count = n\n",
    "        assert desc1.ndim == 2\n",
    "        # feature count = m\n",
    "        assert desc2.ndim == 2\n",
    "        # the two features should have the type\n",
    "        assert desc1.shape[1] == desc2.shape[1]\n",
    "\n",
    "        if desc1.shape[0] == 0 or desc2.shape[0] == 0:\n",
    "            return []\n",
    "\n",
    "        # TODO 8: Perform ratio feature matching.\n",
    "        # This uses the ratio of the SSD distance of the two best matches\n",
    "        # and matches a feature in the first image with the closest feature in the\n",
    "        # second image.\n",
    "        # Note: multiple features from the first image may match the same\n",
    "        # feature in the second image.\n",
    "        # You don't need to threshold matches in this function\n",
    "        # TODO-BLOCK-BEGIN\n",
    "        raise Exception(\"TODO in features.py not implemented\")\n",
    "        # TODO-BLOCK-END\n",
    "\n",
    "        return matches\n",
    "\n",
    "\n",
    "class ORBFeatureMatcher(FeatureMatcher):\n",
    "    def __init__(self):\n",
    "        self.bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "        super(ORBFeatureMatcher, self).__init__()\n",
    "\n",
    "    def matchFeatures(self, desc1, desc2):\n",
    "        return self.bf.match(desc1.astype(np.uint8), desc2.astype(np.uint8))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
